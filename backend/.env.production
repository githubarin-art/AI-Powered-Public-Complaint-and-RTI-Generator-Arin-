# Production environment template for Render
# Copy this to .env or set in Render Dashboard

# ===================
# Server Configuration
# ===================
ENVIRONMENT=production
DEBUG=false
BACKEND_HOST=0.0.0.0
BACKEND_PORT=8000

# ===================
# CORS Configuration
# Update with your actual Vercel deployment URL
# Format: JSON array or comma-separated values
# ===================
# Option 1: JSON array (recommended)
CORS_ORIGINS=["https://your-app-name.vercel.app","http://localhost:3000"]
# Option 2: Comma-separated
# CORS_ORIGINS=https://your-app-name.vercel.app,http://localhost:3000

# ===================
# NLP Configuration
# Note: DistilBERT disabled by default to save memory on free tier (512MB)
# ===================
SPACY_MODEL=en_core_web_sm
ENABLE_DISTILBERT=false
# DISTILBERT_MODEL=distilbert-base-uncased  # Only if ENABLE_DISTILBERT=true

# ===================
# Confidence Thresholds
# ===================
CONFIDENCE_HIGH=0.9
CONFIDENCE_MEDIUM=0.7
CONFIDENCE_LOW=0.5

# ===================
# Rate Limiting
# ===================
RATE_LIMIT_ENABLED=true
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW_SECONDS=60

# ===================
# Logging
# ===================
LOG_LEVEL=INFO
LOG_TO_FILE=false

# ===================
# Security
# ===================
API_KEY_ENABLED=false

# ===================
# OpenAI Configuration (Optional)
# Set this in Render Dashboard for security
# ===================
# OPENAI_API_KEY=sk-your-key-here
OPENAI_MODEL=gpt-4o-mini
OPENAI_MAX_TOKENS=1500
OPENAI_TEMPERATURE=0.3
ENABLE_LLM_ENHANCEMENT=true

# ===================
# Feature Flags
# ===================
FEATURE_HINDI_SUPPORT=true
FEATURE_XLSX_EXPORT=true
FEATURE_AUDIT_LOG=true
FEATURE_LLM_ASSIST=true
